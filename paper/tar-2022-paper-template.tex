% Paper template for TAR 2022
% (C) 2014 Jan Šnajder, Goran Glavaš, Domagoj Alagić, Mladen Karan
% TakeLab, FER

\documentclass[10pt, a4paper]{article}

\usepackage{tar2022}

\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[hidelinks]{hyperref}

\title{Making your tweets more ironic}

\name{Kristian Djaković, Rene Kustura, Toma Puljak} 

\address{
University of Zagreb, Faculty of Electrical Engineering and Computing\\
Unska 3, 10000 Zagreb, Croatia\\ 
\texttt{\{author\}@fer.hr}\\
}
          
         
\abstract{ 
With this paper, we present you the words that will make your tweets more ironic. The process of choosing which words have the biggest imapct to the irony started with RoBERTa model. The model was used for classification purposes. Once we found the ironic the tweet by using the attention as an interpretation metric we could see which word had the biggest impact to the desicion. Once we found the list of words, we took the words and non ironic tweets and try to make them ironic.
}

\begin{document}

\maketitleabstract

\section{Introduction}

Irony is complicated.
In general, irony refers to a clash between the expectation and outcome of an expression. \citep{kreutz-20}. 
While this definition looks simple enough, detecting irony in text proves to be a difficult task, not only for models but for people as well.
This paper tackles the question: "What makes tweets ironic?" by analysing attention values outputted from a classification model.

The attention mechanism allows modeling of dependencies without regard to their distance in the input or output sequence \citep{all-you-need}.
What's great about attention is that it adds a layer of explainability to the model. Attention values can be used to interpret the focus of a model when completing various tasks.
In this paper, attention values are used to gather the most ironic tokens from data samples. The most ironic tokens are those with the highest attention values.

For classification purposes, we used a pretrained RoBERTa Transformer model that was trained on the SemEval2018 Irony Detection dataset \citep{roberta}.
The model uses multi-head attention, thus we used the \textit{attention rollout} method to aggregate attention values across heads for single tokens and connections between token pairs.

Once we gathered the most ironic tokens, we applied them to tweets that the model classified as \textit{non ironic} and observed the change between the prediction certainty.
We use this change in prediction certainty as a metric to evaluate how much a token, or token pair, impacts the ironic sentiment of a given tweet.

\section{Background}

In this section, we provide an overview of the classification model setup, attention aggregation methods, and the datasets to evaluate our analysis goal.

\subsection{Model Setup}
\label{sec:first}

For classification purposes, we used a pretrained RoBERTa Transformer model that had the best performance in irony detection.
The model can be found here: \url{https://huggingface.co/cardiffnlp/twitter-roberta-base-irony}.
RoBERTa is a retrained BERT model with improved performance. The details of the architecture can be found in \citep{roberta}. 

\subsection{Attention as an Interpretation Metric}

Using attention as an interpretation metric is arguable and research by \cite{attention-interpretable} shows that it doesn't necessarily produce correct importance ranking.
Nonetheless, we use attention values to interpret how ironic are the tokens, or token pairs.

We considered the alternative of analysing all tokens from selected ironic tweets, but that would require a lot of computation time which we leave for future work.

\subsection{Attention Aggregation}
\label{sec:attaggr}

To aggregate attention values into a singular output, we use the \textit{attention rollout} method.
Attention rollout is a recursive method that calculates the product of all attention weights in the attention graph. \citep{quantifying-attention-flow}
This method will compute a singular output for a single token (node) that we feed into it and if we squeeze the resulting matrix without extraction, we get attention values for two connected tokens in the input sentence.

\subsection{Data}

The dataset used to train the RoBERTa model for irony detection is the SemEval2018 Irony Detection dataset \citep{van-hee-etal-2018-semeval} which is split into training and testing sets.
Each tweet is annotated with a binary label of 0 or 1, representing a non-ironic and ironic label respectively.

We applied a simple preprocessing step for all tweets which changes all user tags to \textit{@user} and removes all URLs.
This step ensures that tagging specific users in tweets doesn't affect the tokenization and that URLs don't affect the model at all because they, by themselves, do not add any semantic value to the tweet.

\section{Analysing the Most Ironic Tokens}

In this section, we will cover the process of finding the most ironic tokens from the used dataset and the methods used for evaluating the results.

\subsection{Finding the Tokens}

The first step in finding the tokens is to extract all tweets that were annotated as ironic from the training and testing datasets, keeping them separate so we can test the results of the experiment separately.
We then classified those tweets using the RoBERTa model to obtain a confidence score for each label.
By sorting the tweets using their ironic label confidence score as a sorting parameter we obtained a list of the most ironic tweets in the datasets, according to the model.
The five most ironic tweets from the training and testing datasets can be seen in Table~\ref{tab:most-ironic-train} and ~\ref{tab:most-ironic-test} respectively.

\begin{table*}
\caption{Most Ironic Tweets in the Training Set}
\label{tab:most-ironic-train}
\begin{center}
\begin{tabular}{llr}
\toprule
Tweet & Confidence score\\
\midrule
Yay for getting pink eye again!  \#whyme                                                & 1 \\
@user yay!!!! It works  \#HateWhenThingsDontWorkRight                                   & 0.99 \\
@user great Christmas.                                                                  & 0.99 \\
Well done @user for making it possible to get emergency messages to a member of staff.  & 0.99 \\
Isn't it great to sleep 5 hours and feel like a million bucks?  \#gettingold            & 0.99 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

\begin{table*}
\caption{Most Ironic Tweets in the Test Set}
\label{tab:most-ironic-test}
\begin{center}
\begin{tabular}{llr}
\toprule
Tweet & Confidence score\\
\midrule
Just great when you're mobile bill arrives by text                                          & 1 \\
OH and now the District line has major signal failures and delays FANTASTIC!!!              & 0.99 \\
A wonderful day of starting work at 6am                                                     & 0.99 \\
Having to be up in four hours sounds great                                                  & 0.99 \\
@user @user @user @user @user  nice to see the ambulance service is so important to OUR mps & 0.99 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

Once we obtained the list of the most ironic tweets, we performed attention aggregation methods outlined in Section~\ref{sec:attaggr} and sort the tokens by the attention score in descending order.
That gives us a list of singular and two connected tokens that the model focused on more while performing classification.
A subset of obtained singular and token pairs for the tweet "Yay for getting pink eye again!  \#whyme" can be seen in Table~\ref{tab:attention-tokens-single} and ~\ref{tab:attention-tokens-pairs} respectively.

\begin{table*}
\caption{Single Tokens With Highest Attention}
\label{tab:attention-tokens-single}
\begin{center}
\begin{tabular}{llr}
\toprule
Token & Attention score\\
\midrule
me    & 1 \\
Y     & 0.37 \\
pink  & 0.33 \\
ay    & 0.29 \\
why   & 0.14 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

\begin{table*}
\caption{Token Pairs With Highest Attention}
\label{tab:attention-tokens-pairs}
\begin{center}
\begin{tabular}{llr}
\toprule
Token1 & Token2 & Attention score\\
\midrule
ay                  & Y & 0.6 \\
\#                  & Y & 0.6 \\
\textvisiblespace   & Y & 0.6 \\
me                  & Y & 0.6 \\
again               & Y & 0.6 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

\subsection{Adding Ironic Tokens to Tweets}

For tweets which we will analyse, we randomly sampled 100 tweets, from the train and test datasets.

To add the ironic tokens into the text we simply appended them to the end of the tweet. This was done for each token in the list applied to each tweet in the subset.
We are aware that simply appending the token, or tokens, to the end of a tweet may generate something meaningless but ensuring that the newly formed tweet is semantically correct is out of the scope of this paper and we leave that for future work.

\section{Results}

\subsection{Single Token}

We analysed (X) tweets paired with 10 tokens. A sample of the top (N) and bottom (M) changes in non-ironic confidence scores can be seen in (ADD TABLE), with the full results available at: (LINK TO GITHUB).

The results show that the token with the most influence on the ironic sentiment was (X) and that token (Y) emphasizes the non ironic sentiment of a tweet. (ADD MORE COMMENTS ON THE RESULTS)

\subsection{Token Pairs}

We analysed 100 tweets paired with the top 10 pairs of tokens from the top 20 most ironic tweets, producing a total of 19799 new tweets. A sample of the top and bottom 3 changes in non-ironic confidence scores in the train set can be seen in Table~\ref{tab:token-pair-train-results}, with the full results available at: (LINK TO GITHUB).

\begin{table*}
\caption{Sample of Token Pair Results on the Train Set}
\label{tab:token-pair-train-results}
\begin{center}
\begin{tabular}{c|c|c|c|c}
\toprule
Index & Tweet & Added Tokens & New Non-Ironic Score & Change\\
\midrule
1     & Gah! Desperately trying to bust this cold!                & Success \textvisiblespace & 0.0267051 & 0.939541  \\
2     & Gah! Desperately trying to bust this cold!                & what great                & 0.0322938 & 0.933953  \\
3     & @BlogOfErised so I gave up and am now heading for bed orz & wow \textvisiblespace     & 0.0543532 & 0.918367  \\
19797 & Why I love penguins of Madagascar \#humor \#reliefcomedy  & music It                  & 0.715983  & -0.552966 \\
19798 & Why I love penguins of Madagascar \#humor \#reliefcomedy  & already @                 & 0.722912  & -0.559895 \\
19799 & Why I love penguins of Madagascar \#humor \#reliefcomedy  & in It                     & 0.733982  & -0.570964 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

The results show that the token pair with the most influence on the ironic sentiment was "Success \textvisiblespace " and that token pair "in It" emphasizes the non ironic sentiment of a tweet.
Taking a look and the entire result list, we see that the tweet "Why I love penguins of Madagascar  \#humor \#reliefcomedy" has been greatly influenced by the appended tokens.
Even though the tweet was actually labeled as ironic before appending the tokens, adding ironic tokens flipped its sentiment to non ironic.

Regarding the tokens that most influenced the ironic sentiment, it is interesting to see token pair "wow \textvisiblespace ".
Intuetively, "wow" can be seen as a sarcastic or ironic token from a semantic perspective, thus we are satisfied with the result.

\section{Future Work}

Even though we have managed to change ironic sentiment by applying ironic tokens to tweets, we propose a more robust approach that takes into account that the semantics of a tweet remains intact after adding the token.
Additionally, possible exploration of adding tokens at arbitrary points in the tweet, not only at the end.

As mentioned, a higher attention score doesn't necessarily mean that a token is more ironic, thus in future work, we could explore different metrics for obtaining tokens that we want to analyse.

\section{Conclusion}

Conclusion is the last enumerated section of the paper. It should not exceed half of a column and is typically split into 2--3 paragraphs. No new information should be presented in the conclusion; this section only summarizes and concludes the paper.

\bibliographystyle{tar2022}
\bibliography{tar2022} 

\end{document}

% \section{Figures and tables}

% \subsection{Figures}

% Here is an example on how to include figures in the paper. Figures are included in \LaTeX{} code immediately \textit{after} the text in which these figures are referenced. Allow \LaTeX{} to place the figure where it believes is best (usually on top of the page of at the position where you would not place the figure). Figures are referenced as follows: ``Figure~\ref{fig:figure1} shows \dots''. Use tilde (\verb.~.) to prevent separation between the word ``Figure'' and its enumeration. 

% \begin{figure}
% \begin{center}
% \includegraphics[width=\columnwidth]{drawing.pdf}
% \caption{This is the figure caption. Full sentences should be followed with a dot. The caption should be placed \textit{below} the figure. Caption should be short; details should be explained in the text.}
% \label{fig:figure1}
% \end{center}
% \end{figure}

% \section{Math expressions and formulas}

% Math expressions and formulas that appear within the sentence should be written inside the so-called \emph{inline} math environment: $2+3$, $\sqrt{16}$, $h(x)=\mathbf{1}(\theta_1 x_1 + \theta_0>0)$. Larger expressions and formulas (e.g., equations) should be written in the so-called \emph{displayed} math environment:

% \[
% b^{(i)}_k = \begin{cases}
% 1 & \text{if 
%     $k = \text{argmin}_j \| \mathbf{x}^{(i)} - \mathbf{\mu}_j \|,$}\\
% 0 & \text{otherwise}
% \end{cases}
% \]

% Math expressions which you reference in the text should be written inside the \textit{equation} environment:

% \begin{equation}\label{eq:kmeans-error}
% J = \sum_{i=1}^N \sum_{k=1}^K 
% b^{(i)}_k \| \mathbf{x}^{(i)} - \mathbf{\mu}_k \|^2
% \end{equation}

% Now you can reference equation \eqref{eq:kmeans-error}. If the paragraph continues right after the formula

% \begin{equation}
% f(x) = x^2 + \varepsilon
% \end{equation}

% \noindent like this one does, use the command \emph{noindent} after the equation to remove the indentation of the row. 

% Multi-letter words in the math environment should be written inside the command \emph{mathit}, otherwise \LaTeX{} will insert spacing between the letters to denote the multiplication of values denoted by symbols. For example, compare
% $\mathit{Consistent}(h,\mathcal{D})$ and\\
% $Consistent(h,\mathcal{D})$.

% If you need a math symbol, but you don't know the corresponding \LaTeX{} command that generates it, try
% \emph{Detexify}.\footnote{\texttt{http://detexify.kirelabs.org/}}

% \section{Referencing literature}

% References to other publications should be written in brackets with the last name of the first author and the year of publication, e.g., \citep{chomsky-73}.  Multiple references are written in sequence, one after another, separated by semicolon and without whitespaces in between, e.g., \citep{chomsky-73,chave-64,feigl-58}. References are typically written at the end of the sentence and necessarily before the sentence punctuation.

% If the publication is authored by more than one author, only the name of the first author is written, after which abbreviation \emph{et al.}, meaning \emph{et alia}, i.e.,~and others is written as in \citep{johnson-etc}. If the publication is authored by only two authors, then the last names of both authors are written \citep{johnson-howells}.

% If the name of the author is incorporated into the text of the sentence, it should not be in the brackets (only the year should be there). E.g.,~``\citet{chomsky-73}
% suggested that \dots''. The difference is whether you reference the publication or the author who wrote it. 

% The list of all literature references is given alphabetically at the end of the paper. The form of the reference depends on the type of the bibliographic unit: conference papers,
% \citep{chave-64}, books \citep{butcher-81}, journal articles
% \citep{howells-51}, doctoral dissertations \citep{croft-78}, and book chapters \citep{feigl-58}. 

% All of this is automatically produced when using BibTeX. Insert all the BibTeX entries into the file \texttt{tar2022.bib}, and then reference them via their symbolic names.
